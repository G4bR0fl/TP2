<!DOCTYPE html>
<html>
<title>Good Old Times</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
<link rel="stylesheet" type="text/css" media="screen" href="main.css" />

<body>

  <div class="w3-container w3-blue-gray">
    <div class="w3-bar w3-center">
      <p>
        <h1>Técnicas de Programação 2</h1>
      </p>
      <p>
        <h2>Good Old Times</h2>
      </p>
      <div class="w3-row">
        <div class="w3-col m6">
          <p>Giovanni M Guidini 16/0122660</p>
          <p>Vitor F Dullens 16/0148260</p>
        </div>
        <div class="w3-col m6">
          <p>Thiago V Machado 16/01xxxxx</p>
          <p>Gabriel Bessa 16/0120811</p>
        </div>
      </div>
    </div>
  </div>
  <hr class="header_division">

  <!-- Sidebar -->
  <div class="w3-sidebar w3-light-grey w3-bar-block" style="width:15%">
    <ul class="w3-ul">
      <li class="nav-li"><a href="#background">Background</a></li>
      <li class="nav-li"><a href="#contraints">Restrições</a></li>
      <li class="nav-li"><a href="#example">Exemplo</a></li>
    </ul>
  </div>

  <!-- Page Content -->
  <div class="w3-light-gray page_content">
    <div class="w3-container">
      <h1 style="margin-bottom: 0px;" id="background">Background</h1>
      <hr class="topic_underline">

      <p>Este estilo de programação reflete aquela feita nos primeiros computadores, do início da década de 50. Ele vem
        diretamente do primerio modelo viável de computação, as máquinas de Turing.</p>

      <p>Uma máquina de Turing consiste em uma fita de memória modificável e uma máquina de estados que lê e modifica
        esses estados, assim, só existe a memória. As máquinas de Turing influenciou os modelos de Von Neumman. Essas
        máquinas e modelos levaram aos primeiros computadores e, consequentemente, às primerias linguagens de
        programação.</p>

      <h1 class="topic_style" id="constraints">Restrições</h1>
      <hr class="topic_underline">

      <ul>
        <li>Quantidade muito pequena de memória primária. Geralmente menor do que o tamanho dos dados a serem
          processados/gerados</li>
        <li>Não existem identificadores - variáveis, posições anotadas da memória - apenas posições da memória que
          podem ser referenciadas por números.</li>
      </ul>

      <h1 class="topic_style" id="example">Exemplos</h1>
      <hr class="topic_underline">

    <h3>Hello World</h3>

    <pre>
        """
        Hello World program, Good Old Times style.
        """
        # Small memory, with 1024 positions.
        data = [0] * 1024

        # Add words to memory
        data[0:5] = 'Hello '
        data[6:11] = 'World!'

        # Print message
        data[12] = 0 # index
        while(data[12] < 11):
            print(data[data[12]], end="")   # print char
            data[12] += 1 # index++
        print() # print \n
    </pre>

    <h3>Exemplo do Livro</h3>
    <pre class="prettyprint linenums:1">
        import sys, os, string

        # Utility for handling the intermediate 'secondary memory'
        def touchopen(filename, *args, **kwargs):
            try:
                os.remove(filename)
            except OSError:
                pass
            open(filename, "a").close() # "touch" file
            return open(filename, *args, **kwargs)

        # The constrained memory should have no more than 1024 cells
        data = []
        # We're lucky:
        # The stop words are only 556 characters and the lines are all 
        # less than 80 characters, so we can use that knowledge to 
        # simplify the problem: we can have the stop words loaded in 
        # memory while processing one line of the input at a time.
        # If these two assumptions didn't hold, the algorithm would 
        # need to be changed considerably.

        # Overall strategy: (PART 1) read the input file, count the 
        # words, increment/store counts in secondary memory (a file) 
        # (PART 2) find the 25 most frequent words in secondary memory

        # PART 1: 
        # - read the input file one line at a time
        # - filter the characters, normalize to lower case
        # - identify words, increment corresponding counts in file

        # Load the list of stop words
        f = open('../stop_words.txt')
        data = [f.read(1024).split(',')] # data[0] holds the stop words
        f.close()

        data.append([])    # data[1] is line (max 80 characters)
        data.append(None)  # data[2] is index of the start_char of word
        data.append(0)     # data[3] is index on characters, i = 0
        data.append(False) # data[4] is flag indicating if word was found
        data.append('')    # data[5] is the word
        data.append('')    # data[6] is word,NNNN
        data.append(0)     # data[7] is frequency

        # Open the secondary memory
        word_freqs = touchopen('word_freqs', 'rb+')
        # Open the input file
        f = open(sys.argv[1])
        # Loop over input file's lines
        while True:
            data[1] = [f.readline()] 
            if data[1] == ['']: # end of input file
                break
            if data[1][0][len(data[1][0])-1] != '\n': # If it does not end with \n
                data[1][0] = data[1][0] + '\n' # Add \n
            data[2] = None
            data[3] = 0 
            # Loop over characters in the line
            for c in data[1][0]: # elimination of symbol c is exercise
                if data[2] == None:
                    if c.isalnum():
                        # We found the start of a word
                        data[2] = data[3]
                else:
                    if not c.isalnum():
                        # We found the end of a word. Process it
                        data[4] = False 
                        data[5] = data[1][0][data[2]:data[3]].lower()
                        # Ignore words with len < 2, and stop words
                        if len(data[5]) >= 2 and data[5] not in data[0]:
                            # Let's see if it already exists
                            while True:
                                data[6] = word_freqs.readline().strip()
                                if data[6] == '':
                                    break;
                                data[7] = int(data[6].split(',')[1])
                                # word, no white space
                                data[6] = data[6].split(',')[0].strip() 
                                if data[5] == data[6]:
                                    data[7] += 1
                                    data[4] = True
                                    break
                            if not data[4]:
                                word_freqs.seek(0, 1) # Needed in Windows
                                word_freqs.writelines("%20s,%04d\n" % (data[5], 1))
                            else:
                                word_freqs.seek(-26, 1)
                                word_freqs.writelines("%20s,%04d\n" % (data[5], data[7]))
                            word_freqs.seek(0,0)
                        # Let's reset
                        data[2] = None
                data[3] += 1
        # We're done with the input file
        f.close()
        word_freqs.flush()

        # PART 2
        # Now we need to find the 25 most frequently occuring words.
        # We don't need anything from the previous values in memory
        del data[:]

        # Let's use the first 25 entries for the top 25 words
        data = data + [[]]*(25 - len(data))
        data.append('') # data[25] is word,freq from file
        data.append(0)  # data[26] is freq

        # Loop over secondary memory file
        while True:
            data[25] = word_freqs.readline().strip()
            if data[25] == '': # EOF
                break
            data[26] = int(data[25].split(',')[1]) # Read it as integer
            data[25] = data[25].split(',')[0].strip() # word
            # Check if this word has more counts than the ones in memory
            for i in range(25): # elimination of symbol i is exercise
                if data[i] == [] or data[i][1] < data[26]:
                    data.insert(i, [data[25], data[26]]) 
                    del data[26] #  delete the last element
                    break
                    
        for tf in data[0:25]: # elimination of symbol tf is exercise
            if len(tf) == 2:
                print tf[0], ' - ', tf[1]
        # We're done
        word_freqs.close()
    </pre>
</div>

    </div>
  </div>
</body>

</html>